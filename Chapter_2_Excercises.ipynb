{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy import stats\n",
    "\n",
    "housing_data = pd.read_csv('downloads/housing.csv')\n",
    "\n",
    "train_set, test_set = train_test_split(housing_data, test_size = 0.2, random_state = 42)\n",
    "\n",
    "housing_data['income_cat'] = pd.cut(housing_data['median_income'], \n",
    "                                     bins =[0., 1.5, 3.0, 4.5, 6., \n",
    "                                            np.inf],labels=[1,2,3,4,5])\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(housing_data, housing_data['income_cat']):\n",
    "    strat_train_set = housing_data.loc[train_index]\n",
    "    strat_test_set = housing_data.loc[test_index]\n",
    "\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop('income_cat', axis=1, inplace=True)\n",
    "\n",
    "housing_data = strat_test_set.copy()\n",
    "\n",
    "housing_data[\"rooms_per_household\"] = housing_data[\"total_rooms\"] / housing_data['households']\n",
    "housing_data[\"bedrooms_per_room\"] = housing_data[\"total_bedrooms\"] / housing_data['total_rooms']\n",
    "housing_data[\"population_per_household\"] = housing_data[\"population\"] / housing_data[\"households\"]\n",
    "\n",
    "housing_data = strat_train_set.drop('median_house_value', axis=1)\n",
    "housing_labels = strat_train_set['median_house_value'].copy()\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "housing_num =housing_data.drop(\"ocean_proximity\", axis = 1)\n",
    "imputer.fit(housing_num)\n",
    "\n",
    "imputer.statistics_\n",
    "housing_num.median().values\n",
    "\n",
    "X = imputer.transform(housing_num)\n",
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)\n",
    "\n",
    "housing_cat = housing_data[['ocean_proximity']]\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot.toarray()\n",
    "cat_encoder.categories_\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True):  \n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room  \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing_data.values)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('attr_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('cat', OneHotEncoder(), cat_attribs)\n",
    "])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing_data)\n",
    "\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "\n",
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "\n",
    "housing_prepared_df = pd.DataFrame(housing_prepared, columns=attributes)\n",
    "\n",
    "X = housing_prepared_df\n",
    "y = housing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: SVR(C=20000.0)\n",
      "Best Paramaters: {'C': 20000.0, 'kernel': 'rbf'}\n",
      "Best Paramaters RMSE Score: 56124.55127818887\n",
      "This model performs worse than the Random Forest Regressor\n"
     ]
    }
   ],
   "source": [
    "#Excercise 1: Try a Support Vector Machine regressor with various hyper parameters such as kernel = 'linear' / 'rbf'. How does the SVR predictor preform?\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "param_grid = [\n",
    "    {'kernel': ['linear', 'rbf'], 'C': [20., 200., 2000., 20000.0]},\n",
    "    {'kernel': ['rbf'], 'C': [2., 20., 200., 2000.0,],\n",
    "    'gamma' : [0.02, 0.2, 2.0]}\n",
    "]\n",
    "\n",
    "svm_grid_search = GridSearchCV(svr, param_grid, cv=5, scoring = 'neg_mean_squared_error')\n",
    "svm_grid_search.fit(X,y)\n",
    "\n",
    "print(f\"Best Estimator: {svm_grid_search.best_estimator_}\")\n",
    "print(f\"Best Paramaters: {svm_grid_search.best_params_}\")\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf', C=20000.0, gamma=0.2)\n",
    "svr_rbf.fit(X,y)\n",
    "\n",
    "svr_rbf_predictions = svr_rbf.predict(X)\n",
    "svr_rbf_mse = mean_squared_error(y, svr_rbf_predictions)\n",
    "svr_rbf_rmse = np.sqrt(svr_rbf_mse)\n",
    "print(f\"Best Paramaters RMSE Score: {svr_rbf_rmse}\")\n",
    "print(\"This model performs worse than the Random Forest Regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: SVR(C=16683.860588281554, gamma=0.26497040005002437)\n",
      "Best Paramaters: {'C': 16683.860588281554, 'gamma': 0.26497040005002437, 'kernel': 'rbf'}\n",
      "Best Paramaters RMSE Score: 56254.321416577426\n"
     ]
    }
   ],
   "source": [
    "#Excercise 2: Try replacing GridSearchCV with RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, expon\n",
    "\n",
    "param_dist = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': reciprocal(20,20000),\n",
    "    'gamma' : expon(scale=1.0)\n",
    "    }\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "svr_rand_search = RandomizedSearchCV(svr, param_distributions=param_dist, n_iter=25, cv=5, scoring = 'neg_mean_squared_error', random_state=42)\n",
    "svr_rand_search.fit(X,y)\n",
    "\n",
    "print(f\"Best Estimator: {svr_rand_search.best_estimator_}\")\n",
    "print(f\"Best Paramaters: {svr_rand_search.best_params_}\")\n",
    "svr_rbf_rand = SVR(kernel='rbf', C=16684.0, gamma=0.27)\n",
    "svr_rbf_rand.fit(X,y)\n",
    "\n",
    "svr_rbf_rand_predictions = svr_rbf_rand.predict(X)\n",
    "svr_rbf_rand_mse = mean_squared_error(y, svr_rbf_rand_predictions)\n",
    "svr_rbf_rand_rmse = np.sqrt(svr_rbf_rand_mse)\n",
    "print(f\"Best Paramaters RMSE Score: {svr_rbf_rand_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['longitude' 'latitude' 'median_income' 'pop_per_hhold' 'INLAND']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.94135046,  1.34743822, -0.8936472 ,  0.00622264,  1.        ],\n",
       "       [ 1.17178212, -1.19243966,  1.292168  , -0.04081077,  0.        ],\n",
       "       [ 0.26758118, -0.1259716 , -0.52543365, -0.07537122,  1.        ]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Excercise 3: Try adding a transformer in the preparation pipeline to select only the most important attributes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing_data)\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "rfr.fit(housing_prepared_df, housing_labels)\n",
    "rfr_feature_importances = rfr.feature_importances_\n",
    "\n",
    "def indices_of_top_k(arr, k):\n",
    "    return np.sort(np.argpartition(np.array(arr), -k)[-k:])\n",
    "\n",
    "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_importances, k):\n",
    "        self.feature_importances = feature_importances\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[:, self.feature_indices_]\n",
    "\n",
    "k = 5\n",
    "top_k_feature_indices = indices_of_top_k(rfr_feature_importances, k)\n",
    "\n",
    "print(np.array(attributes)[top_k_feature_indices])\n",
    "\n",
    "prep_feature_selection_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(rfr_feature_importances, k))\n",
    "])\n",
    "\n",
    "housing_prepared_top_k_features = prep_feature_selection_pipeline.fit_transform(housing_data)\n",
    "housing_prepared[0:3, top_k_feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [ 86692.13281441 286840.7959524   99826.52170369 149805.01711305]\n",
      "Actual Prices: [72100.0, 279600.0, 82700.0, 112500.0]\n"
     ]
    }
   ],
   "source": [
    "#Excercise 4: Try creating a single pipeline that does the full data preperation plus the final prediction\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, expon\n",
    "\n",
    "param_dist = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': reciprocal(20,20000),\n",
    "    'gamma' : expon(scale=1.0)\n",
    "    }\n",
    "\n",
    "svr_rand_search = RandomizedSearchCV(svr, param_distributions=param_dist, n_iter=25, cv=5, scoring = 'neg_mean_squared_error', random_state=42)\n",
    "svr_rand_search.fit(X,y)\n",
    "\n",
    "prep_select_predict_pipeline = Pipeline([\n",
    "    ('preperation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(rfr_feature_importances, k)),\n",
    "    ('rfr', SVR(**svr_rand_search.best_params_))\n",
    "])\n",
    "\n",
    "prep_select_predict_pipeline.fit(housing_data, housing_labels)\n",
    "\n",
    "some_data = housing_data.iloc[:4]\n",
    "some_labels = housing_labels.iloc[:4]\n",
    "\n",
    "print(\"Predictions:\", prep_select_predict_pipeline.predict(some_data))\n",
    "print(\"Actual Prices:\", list(some_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
